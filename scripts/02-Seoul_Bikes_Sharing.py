# -*- coding: utf-8 -*-
"""Seoul-Bikes-Sharing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wMuTJi8F3sHxYJar0RIRxFbta8ZqBALN

# Seoul Bikes Sharing
The dataset contains count of public bicycles rented per hour in the Seoul Bike Sharing System, with corresponding weather data and holiday information

## Source
Seoul Bike Sharing Demand [Dataset]. (2020). UCI Machine Learning Repository. https://doi.org/10.24432/C5F62R.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from imblearn.over_sampling import RandomOverSampler
from sklearn.preprocessing import StandardScaler
import copy
import seaborn as sns
import tensorflow as tf
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

cols = ['Date','Rented_Bike_Count','Hour','Temperature','Humidity','Wind_speed','Visibility','Dew_Pt_Temperature','Solar_Radiation','Rainfall','Snowfall','Seasons','Holiday','Functioning']
df = pd.read_csv('seoul_bike_data.csv')
df.columns = cols
df.head()

df = df.drop(['Date', 'Holiday', 'Seasons','Hour'], axis =1)
df.head()

df['Functioning'] = (df['Functioning'] == 'Yes').astype(int)
df.head()

for label in df.columns[1:]:
  plt.scatter(df[label], df['Rented_Bike_Count'])
  plt.xlabel(label)
  plt.ylabel('Rented_Bike_Count')
  plt.show()

df = df.drop(['Wind_speed','Visibility','Functioning'], axis =1)
df.head()

"""# Train, Validation, Test Datasets"""

train, valid, test = np.split(df.sample(frac=1),[int(len(df) * 0.6), int(len(df) * 0.8)])

def scale_dataset(dataframe, y_label, X_label=None,over_sampling=False):
  df = copy.deepcopy(dataframe)
  if X_label is None:
    X_label = [c for c in df.columns if c != y_label]
    X = df[X_label].values

  elif len(X_label) == 1:
    X = df[X_label].values
    X = np.reshape(X, (-1, 1))
  else:
    X = df[X_label].values

  X = StandardScaler().fit_transform(X)
  y= df[y_label].values

  if over_sampling:
    X, y = RandomOverSampler().fit_resample(X, y)

  y= np.reshape(y,(-1,1))

  data = np.hstack((X, y))

  return data, X, y

"""# Linear Regression
Simple regression, with just 1 feature Temperature
"""

_, X_train_temp, y_train_temp = scale_dataset(train, 'Rented_Bike_Count',['Temperature'], over_sampling = True)
_, X_valid_temp, y_valid_temp = scale_dataset(valid, 'Rented_Bike_Count',['Temperature'])
_, X_test_temp, y_test_temp = scale_dataset(test, 'Rented_Bike_Count',['Temperature'])

temp_model = LinearRegression()
temp_model.fit(X_train_temp, y_train_temp)

y_pred_temp = temp_model.predict(X_test_temp)

temp_model.score(X_test_temp, y_test_temp) #R2 score

print(f"MAE : {mean_absolute_error(y_test_temp,y_pred_temp)}")
print(f"MSE : {mean_squared_error(y_test_temp,y_pred_temp)}")
print(f"R2 : {r2_score(y_test_temp,y_pred_temp)}")

plt.scatter(X_train_temp,y_train_temp,color ='Blue',label='Training Data')
# plt.plot(X_test_temp,y_pred_temp,color='Red',label='Regression Line')
x = tf.linspace(-2,2,100)
x = np.reshape(x,(-1,1))
plt.plot(x,np.reshape(temp_model.predict(x),(-1,)), color='Red',label='Regression Line')
plt.ylabel('Rented Bikes Count')
plt.xlabel('Temperature')
plt.legend()
plt.title('Bikes Vs Temperature')
plt.show()

"""Multiple Linear Regression"""

_, X_train, y_train = scale_dataset(train, 'Rented_Bike_Count', over_sampling = True)
_, X_valid, y_valid = scale_dataset(valid, 'Rented_Bike_Count')
_, X_test, y_test = scale_dataset(test, 'Rented_Bike_Count')

reg_model = LinearRegression()
reg_model.fit(X_train, y_train)

reg_model.score(X_test, y_test)  # R2

y_pred = reg_model.predict(X_test)

print(f"MAE: {mean_absolute_error(y_test, y_pred)}")
print(f"MSE: {mean_squared_error(y_test, y_pred)}")
print(f"R2: {r2_score(y_test, y_pred)}")

"""# Regression with Neural Networks
Simple Regression
"""

def plot_loss(history):
  plt.plot(history.history['loss'], label='loss')
  plt.plot(history.history['val_loss'], label='val_loss')
  plt.xlabel('Epoch')
  plt.ylabel('MSE')
  plt.legend()
  plt.grid(True)
  plt.show()

_, X_train_temp, y_train_temp = scale_dataset(train, 'Rented_Bike_Count',['Temperature'], over_sampling = True)
_, X_valid_temp, y_valid_temp = scale_dataset(valid, 'Rented_Bike_Count',['Temperature'])
_, X_test_temp, y_test_temp = scale_dataset(test, 'Rented_Bike_Count',['Temperature'])

temp_normalizer = tf.keras.layers.Normalization(input_shape=(1,), axis= None)
temp_normalizer.adapt(X_train_temp.reshape(-1))
temp_nn_model = tf.keras.Sequential([
    temp_normalizer,
    tf.keras.layers.Dense(1)
])
temp_nn_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mean_squared_error')

history = temp_nn_model.fit(
    X_train_temp.reshape(-1), y_train_temp,
    verbose=0,
    epochs=50,
    validation_data=(X_valid_temp, y_valid_temp)
)

plot_loss(history)

plt.scatter(X_train_temp, y_train_temp, label="Data", color="blue")
x = tf.linspace(-2, 2, 100)
plt.plot(x, temp_nn_model.predict(np.array(x).reshape(-1, 1)), label="Fit", color="red", linewidth=3)
plt.legend()
plt.title("Bikes vs Temp")
plt.ylabel("Number of bikes")
plt.xlabel("Temp")
plt.show()

"""# Neural Network
Simple Regression
"""

_, X_train_temp, y_train_temp = scale_dataset(train, 'Rented_Bike_Count',['Temperature'], over_sampling = True)
_, X_valid_temp, y_valid_temp = scale_dataset(valid, 'Rented_Bike_Count',['Temperature'])
_, X_test_temp, y_test_temp = scale_dataset(test, 'Rented_Bike_Count',['Temperature'])

temp_normalizer = tf.keras.layers.Normalization(input_shape=(1,), axis=None)
temp_normalizer.adapt(X_train_temp.reshape(-1))

nn_model = tf.keras.Sequential([
    temp_normalizer,
    tf.keras.layers.Dense(32,activation='relu'),
    tf.keras.layers.Dense(32,activation='relu'),
    tf.keras.layers.Dense(32,activation='relu'),
    tf.keras.layers.Dense(1)
])

nn_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mean_squared_error')

history = nn_model.fit(
    X_train_temp.reshape(-1), y_train_temp,
    verbose=0,
    epochs=50,
    validation_data=(X_valid_temp, y_valid_temp)
)

plot_loss(history)

plt.scatter(X_train_temp, y_train_temp, label="Data", color="blue")
x = tf.linspace(-2, 2, 100)
plt.plot(x, nn_model.predict(np.array(x).reshape(-1, 1)), label="Fit", color="red", linewidth=3)
plt.legend()
plt.title("Bikes vs Temp")
plt.ylabel("Number of bikes")
plt.xlabel("Temp")
plt.show()

"""Multiple Regression"""

_, X_train, y_train = scale_dataset(train, 'Rented_Bike_Count', over_sampling = True)
_, X_valid, y_valid = scale_dataset(valid, 'Rented_Bike_Count')
_, X_test, y_test = scale_dataset(test, 'Rented_Bike_Count')

normalizer = tf.keras.layers.Normalization(input_shape=(6,), axis=-1)
normalizer.adapt(X_train)

nn_model = tf.keras.Sequential([
    normalizer,
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dense(1)
])
nn_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mean_squared_error')

history = nn_model.fit(
    X_train, y_train,
    validation_data=(X_valid, y_valid),
    verbose=0, epochs=50
)

plot_loss(history)

y_pred_nn = nn_model.predict(X_test)
y_pred_lin = reg_model.predict(X_test)

plt.scatter(y_test,y_pred_nn,label='Neural Net',alpha=0.7)
plt.scatter(y_test,y_pred_lin,label='Linear Regression',alpha=0.7)
min_val = min(y_test.min(),y_pred_nn.min(),y_pred_lin.min())
max_val = max(y_test.max(),y_pred_nn.max(),y_pred_lin.max())
plt.plot([min_val,max_val],[min_val,max_val], label='Perfect Prediction', color='red')
plt.xlabel('True Values')
plt.ylabel('Predictions')
plt.legend()
plt.show()

